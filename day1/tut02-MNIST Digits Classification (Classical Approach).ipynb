{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC 2017\n",
    "# 2nd July 2017, Tutorial 2\n",
    "# MNIST Digits Classification (Classical Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST database (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Consists of four files: <br>\n",
    "* train-images-idx3-ubyte.gz:  training set images (9912422 bytes) <br>\n",
    "* train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) <br>\n",
    "* t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) <br>\n",
    "* t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)  <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pickle\n",
    "from skimage import feature\n",
    "import struct\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "if not os.path.exists('tut02-results'):\n",
    "    os.makedirs('tut02-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (60000, 28, 28)\n",
      "Train label size: (60000,)\n",
      "Test data size: (10000, 28, 28)\n",
      "Train label size: (10000,)\n",
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf2448a490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "# Training data\n",
    "with open('data/tut02/mnist/train-labels.idx1-ubyte', 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        train_label = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open('data/tut02/mnist/train-images.idx3-ubyte', 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        train_data = np.fromfile(fimg, dtype=np.uint8).reshape(len(train_label), rows, cols)\n",
    "        \n",
    "# Testing data\n",
    "with open('data/tut02/mnist/t10k-labels.idx1-ubyte', 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        test_label = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open('data/tut02/mnist/t10k-images.idx3-ubyte', 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        test_data = np.fromfile(fimg, dtype=np.uint8).reshape(len(test_label), rows, cols)\n",
    "        \n",
    "print('Train data size: '+str(train_data.shape))\n",
    "print('Train label size: '+str(train_label.shape))\n",
    "print('Test data size: '+str(test_data.shape))\n",
    "print('Train label size: '+str(test_label.shape))\n",
    "\n",
    "# Sample data\n",
    "imshow(train_data[0],'gray')\n",
    "print('Label: '+str(train_label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature extraction and data preparation\n",
    "# Training features\n",
    "train_greycoHomFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='homogeneity') for x in list(train_data)]\n",
    "train_greycoConFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='contrast') for x in list(train_data)]\n",
    "train_greycoEnFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='energy') for x in list(train_data)]\n",
    "train_greycoCorrFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='correlation') for x in list(train_data)]\n",
    "train_hogFeat = [feature.hog(x, orientations=4, pixels_per_cell=(5,5)) for x in list(train_data)]\n",
    "train_lbpFeat = [feature.local_binary_pattern(x, 5, 3) for x in list(train_data)]\n",
    "\n",
    "# Testing features\n",
    "test_greycoHomFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='homogeneity') for x in list(test_data)]\n",
    "test_greycoConFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='contrast') for x in list(test_data)]\n",
    "test_greycoEnFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='energy') for x in list(test_data)]\n",
    "test_greycoCorrFeat = [feature.greycoprops(feature.greycomatrix(x, [1], [np.pi/4],normed=True),prop='correlation') for x in list(test_data)]\n",
    "test_hogFeat = [feature.hog(x, orientations=4, pixels_per_cell=(5,5)) for x in list(test_data)]\n",
    "test_lbpFeat = [feature.local_binary_pattern(x, 5, 3) for x in list(test_data)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "trainFeat = np.zeros((60000,1896))\n",
    "for num in range(60000):    \n",
    "    trainFeat[num][:] = np.concatenate((train_greycoHomFeat[num].reshape(1,),train_greycoConFeat[num].reshape(1,),\n",
    "                            train_greycoEnFeat[num].reshape(1,),train_greycoCorrFeat[num].reshape(1,),\n",
    "                                        train_hogFeat[num],train_lbpFeat[num].reshape(28*28),train_data[num].reshape(28*28)),axis=0)\n",
    "\n",
    "testFeat = np.zeros((10000,1896))\n",
    "for num in range(10000):    \n",
    "    trainFeat[num][:] = np.concatenate((test_greycoHomFeat[num].reshape(1,),test_greycoConFeat[num].reshape(1,),\n",
    "                            test_greycoEnFeat[num].reshape(1,),test_greycoCorrFeat[num].reshape(1,),\n",
    "                                        test_hogFeat[num],test_lbpFeat[num].reshape(28*28),test_data[num].reshape(28*28)),axis=0)\n",
    "trainFeat_scaled = preprocessing.scale(trainFeat)\n",
    "testFeat_scaled = preprocessing.scale(testFeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('tut02-results/trainFeat_scaled.pkl','wb') as f:\n",
    "    pickle.dump(trainFeat_scaled,f)\n",
    "with open('tut02-results/testFeat_scaled.pkl','wb') as f:\n",
    "    pickle.dump(testFeat_scaled,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.00709560\n",
      "Iteration 2, loss = 0.84991739\n",
      "Iteration 3, loss = 0.80926330\n",
      "Iteration 4, loss = 0.78343154\n",
      "Iteration 5, loss = 0.76217766\n",
      "Iteration 6, loss = 0.74173220\n",
      "Iteration 7, loss = 0.72489728\n",
      "Iteration 8, loss = 0.70789063\n",
      "Iteration 9, loss = 0.69063643\n",
      "Iteration 10, loss = 0.67517406\n",
      "Iteration 11, loss = 0.65909001\n",
      "Iteration 12, loss = 0.64398507\n",
      "Iteration 13, loss = 0.62917175\n",
      "Iteration 14, loss = 0.61459773\n",
      "Iteration 15, loss = 0.60063437\n",
      "Iteration 16, loss = 0.58721732\n",
      "Iteration 17, loss = 0.57405328\n",
      "Iteration 18, loss = 0.55917347\n",
      "Iteration 19, loss = 0.54686804\n",
      "Iteration 20, loss = 0.53739046\n",
      "Iteration 21, loss = 0.52346930\n",
      "Iteration 22, loss = 0.51008790\n",
      "Iteration 23, loss = 0.49758825\n",
      "Iteration 24, loss = 0.48684645\n",
      "Iteration 25, loss = 0.47715227\n",
      "Iteration 26, loss = 0.46384892\n",
      "Iteration 27, loss = 0.45277977\n",
      "Iteration 28, loss = 0.44099510\n",
      "Iteration 29, loss = 0.42916387\n",
      "Iteration 30, loss = 0.41766372\n",
      "Iteration 31, loss = 0.41086157\n",
      "Iteration 32, loss = 0.40244665\n",
      "Iteration 33, loss = 0.39628031\n",
      "Iteration 34, loss = 0.38288767\n",
      "Iteration 35, loss = 0.37210157\n",
      "Iteration 36, loss = 0.35963425\n",
      "Iteration 37, loss = 0.35505548\n",
      "Iteration 38, loss = 0.34659195\n",
      "Iteration 39, loss = 0.33904798\n",
      "Iteration 40, loss = 0.32833183\n",
      "Iteration 41, loss = 0.32098087\n",
      "Iteration 42, loss = 0.32287827\n",
      "Iteration 43, loss = 0.30937549\n",
      "Iteration 44, loss = 0.30529341\n",
      "Iteration 45, loss = 0.30151551\n",
      "Iteration 46, loss = 0.29013822\n",
      "Iteration 47, loss = 0.28376506\n",
      "Iteration 48, loss = 0.27586721\n",
      "Iteration 49, loss = 0.27124813\n",
      "Iteration 50, loss = 0.26032616\n",
      "Iteration 51, loss = 0.25019084\n",
      "Iteration 52, loss = 0.24406493\n",
      "Iteration 53, loss = 0.23417851\n",
      "Iteration 54, loss = 0.23118057\n",
      "Iteration 55, loss = 0.21979401\n",
      "Iteration 56, loss = 0.21443789\n",
      "Iteration 57, loss = 0.20680862\n",
      "Iteration 58, loss = 0.20070330\n",
      "Iteration 59, loss = 0.19461184\n",
      "Iteration 60, loss = 0.19305097\n",
      "Iteration 61, loss = 0.18923395\n",
      "Iteration 62, loss = 0.18311966\n",
      "Iteration 63, loss = 0.17441608\n",
      "Iteration 64, loss = 0.16715887\n",
      "Iteration 65, loss = 0.16342190\n",
      "Iteration 66, loss = 0.15968265\n",
      "Iteration 67, loss = 0.15606845\n",
      "Iteration 68, loss = 0.15524212\n",
      "Iteration 69, loss = 0.15289162\n",
      "Iteration 70, loss = 0.14268075\n",
      "Iteration 71, loss = 0.14028131\n",
      "Iteration 72, loss = 0.13676174\n",
      "Iteration 73, loss = 0.13237375\n",
      "Iteration 74, loss = 0.13025594\n",
      "Iteration 75, loss = 0.12983625\n",
      "Iteration 76, loss = 0.12983726\n",
      "Iteration 77, loss = 0.14092549\n",
      "Iteration 78, loss = 0.15947132\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#scikitlearn documentation for MLP classifier: goo.gl/F1Q1Fa\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=1e-2)\n",
    "nn.fit(trainFeat_scaled, train_label)       \n",
    "prediction = nn.predict(testFeat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.961583\n",
      "Test set score: 0.097400\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % nn.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % nn.score(testFeat_scaled, test_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
